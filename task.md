# ФИНАЛЬНЫЙ ПРОЕКТ: ОПИСАНИЕ И ТРЕБОВАНИЯ
## Дедлайн

31.12.2025
Поздравляем с приближением к завершению курса! Финальный проект – это ваша возможность продемонстрировать все полученные знания и навыки в области MLOps на практике. В отличие от предыдущих заданий, где мы давали конкретную задачу, теперь вам предстоит придумать и реализовать свой собственный Pet-проект.
Цель финального проекта
Не обязательно в создании нового для рынка продукта, а в построении целостной, надежной и воспроизводимой MLOps-системы, которая решает понятную бизнес-задачу.
Задача
Выберите любую понятную вам проблему (например, прогноз спроса, классификация текстов/изображений, детекция аномалий, рекомендательная система), которая существует в бизнесе при работе с пользователями. Разработайте базовое ML решение и превратите его в работающий сервис.
Компоненты вашего проекта
Ваша система должна быть реализована с использованием Docker и может включать следующие компоненты:
1.	Бизнес-ценность (обязательно):
o	В README, кроме технических деталей, должна быть секция, которая четко и кратко описывает, какую проблему решает ваш сервис и какую ценность он несет для гипотетического бизнеса или пользователя
o	Кроме того, мы просим вас подготовить one-pager с описанием вашего сервиса. Формат – один слайд / страница A4 в формате .pdf/md/html, на котором приведено саммари по вашему сервису (какую бизнес задачу решает, какие данные и использует, какой стек; если есть метрики, то замеры по пропускной способности)
2.	Воспроизводимость и Документация (обязательно):
o	Весь проект должен быть упакован с помощью docker-compose.yml – одна команда для запуска всей системы.
o	README.md с архитектурной схемой (можно нарисовать в draw.io и добавить картинку) и четкими инструкциями по запуску.
o	Файл requirements.txt (или аналоги) для всех Python-зависимостей.
3.	ML-сервис: Приложение, которое использует машинное обучение для решения задачи (инференс). Обучение модели может быть вынесено за скобки (offline), но сам инференс должен происходить внутри сервиса. 
4.	База данных: Использование СУБД (например PostgreSQL, Clickhouse, Redis и другие) для хранения данных, результатов предсказаний, метаданных или features.
5.	Шедулер c ETL: использование Airflow/Dagster/dbt для формирования витрин, расчетов фичей или предсказаний оффлайн по расписанию.
6.	Брокер сообщений: Использование Kafka (или аналоги, например, RabbitMQ) для асинхронной обработки данных. Это может быть поток данных для инференса или поток с результатами предсказаний.
7.	Простой UI: Веб-интерфейс (например, на Streamlit, Taipy, Gradio или Flask), который позволяет:
o	Взаимодействовать с моделью (отправлять данные для предсказания и получать результат, либо запускать симуляцию/генерацию данных для демонстрации работы сервиса).
o	Просматривать историю предсказаний или ключевую бизнес-метрику из базы данных.
8.	Мониторинг: Простой дашборд в Grafana, подключенный к вашей базе данных или данным приложения, который визуализирует ключевые метрики (например, количество запросов, распределение скоров, количество положительных/ отрицательных классов).

## Оценивание проекта
[Оценка 6-7 баллов]
•	Проект загружен в публичный репозиторий GitHub
•	Проект не использует датасеты из домашних заданий на курсе. Это должен быть новый сервис
•	docker-compose.yml стабильно поднимает все обязательные сервисы (ML-сервис, базу данных, брокер, UI, и пр.)
•	README.md содержит описание бизнес-задачи, архитектурную схему и понятную инструкцию по запуску
•	Проект работает в соответствии с описанием
[Оценка 8-10 баллов]
Реализованы все требования на 6-7 баллов, плюс минимум два из следующих пунктов повышенной сложности:
1.	Расширенный мониторинг и логирование: В Grafana добавлены метрики, специфичные для вашей бизнес-задачи (например, Accuracy/Precision в режиме, близком к реальному времени; и бизнес метрики), а также настроено логирование важных событий в системе (например, ELK-стек или просто сбор логов в файл).
2.	Функционал переобучения/апдейта модели: Реализован механизм, позволяющий обновить модель в сервисе без полной остановки системы (например, по сигналу извне или по расписанию с помощью оркестраторов – например, Airflow)
3.	Продвинутый UI: Интерфейс предоставляет не только возможность инференса, но и аналитическую панель с графиками и фильтрами на основе данных, хранящихся в БД. Для вашего ML-сервиса описан спецификацией OpenAPI (Swagger) и доступен через UI.
4.	Сервис инференса: Работает сервис инференса в связке с брокером сообщений
5.	Использование Базы данных с ETL/оркестратором: собираете метрики, фичи, витрины и т.д. по расписанию

## Как отправить результат:
В качестве решения необходимо предоставить ссылку на публичный GitHub репозиторий, содержащий:
•	Весь код проекта.
•	Dockerfile(ы) и docker-compose.yml.
•	Исходники презентации (PDF) – «one-pager», описывающий проект на 1 слайде.
•	README.md с инструкцией по запуску и описанием архитектуры.
Репозиторий должен быть оформлен так, чтобы преподаватель мог без проблем сделать git clone и запустить весь проект одной командой docker-compose up.
Проявите креативность, выберите задачу, которая интересна именно вам, и постройте свою первую полноценную MLOps-систему!
Желаем удачи!

